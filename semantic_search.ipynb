{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ObqL8NjS35lX",
        "outputId": "32d99b79-44c4-4184-d75a-62c4b3aa7823"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nChapter 2: Launching an Application with Proprietary Models \\n    Overview of Proprietary Models\\n    Introduction to OpenAI + Embeddings / GPT3 / ChatGPT\\n    Introduction to Vector Databases\\n    Building a Neural/Semantic Information Retrieval System with Vector Databases, BERT & GPT3\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''\n",
        "Chapter 2: Launching an Application with Proprietary Models\n",
        "    Overview of Proprietary Models\n",
        "    Introduction to OpenAI + Embeddings / GPT3 / ChatGPT\n",
        "    Introduction to Vector Databases\n",
        "    Building a Neural/Semantic Information Retrieval System with Vector Databases, BERT & GPT3\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai\n",
        "from openai import OpenAI\n",
        "from datetime import datetime\n",
        "import hashlib\n",
        "import re\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRLPL8Zd4mhy",
        "outputId": "7e08a3db-70c1-45b8-d2de-97e8beeece03"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.43.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.43.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone_key = os.environ.get('PINECONE_API_KEY')\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\" \")\n",
        ")\n",
        "\n",
        "INDEX_NAME = 'semantic-search'\n",
        "NAMESPACE = 'default'\n",
        "ENGINE = 'text-embedding-ada-002'"
      ],
      "metadata": {
        "id": "y265JyBj6Psn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "\n",
        "pinecone.init(api_key=pinecone_key, environment=\"us-west1-gcp\")"
      ],
      "metadata": {
        "id": "6kDoJN-e6qP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions to get lists of embeddings from the OpenAI API\n",
        "def get_embeddings(texts, engine=ENGINE):\n",
        "    response = client.embeddings.create(\n",
        "        input=texts,\n",
        "        model=engine\n",
        "    )\n",
        "\n",
        "    return [d.embedding for d in list(response.data)]\n",
        "\n",
        "def get_embedding(text):\n",
        "    return get_embeddings([text])[0]\n",
        "\n",
        "len(get_embedding('hi')), len(get_embeddings(['hi', 'hello']))"
      ],
      "metadata": {
        "id": "K9Ptvj5n6q-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not INDEX_NAME in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        INDEX_NAME,  # The name of the index\n",
        "        dimension=1536,  # The dimensionality of the vectors\n",
        "        metric='cosine',  # The similarity metric to use when searching the index\n",
        "        pod_type=\"p1\"  # The type of Pinecone pod\n",
        "    )\n",
        "\n",
        "# Store the index as a variable\n",
        "index = pinecone.Index(INDEX_NAME)"
      ],
      "metadata": {
        "id": "rn4JeECJ7OoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_hash(s):\n",
        "    # Return the MD5 hash of the input string as a hexadecimal string\n",
        "    return hashlib.md5(s.encode()).hexdigest()\n",
        "\n",
        "my_hash('I love to hash it')"
      ],
      "metadata": {
        "id": "M7bUkdHW7RD8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}